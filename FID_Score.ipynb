{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting FID Score from Model Checkpoints\n",
    "\n",
    "To figure out the best checkpoint, we will plot the FID score vs model checkpoint between the generated images from that checkpoint and a set of experimental images. We choose the checkpoint with the lowest FID score.\n",
    "\n",
    "To do this, we need a to create a folder of generated images from each checkpoint. Use `generator.ipynb` to make these folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from scipy.linalg import sqrtm\n",
    "import tensorflow as tf\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from src.make_dataset import process_image, parse_and_save_dir\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID Score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(image_dir):\n",
    "    data_list = []\n",
    "    fn_list = [x for x in os.listdir(image_dir) if \".tif\" in x]\n",
    "    for fn in fn_list:\n",
    "        input_file = image_dir + fn\n",
    "        data = process_image(input_file)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "# calculate frechet inception distance\n",
    "def calculate_fid(model, images1, images2):\n",
    "    # calculate activations\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    \n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff  = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean  = sqrtm(sigma1.dot(sigma2))\n",
    "\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "        \n",
    "    # calculate score\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "\n",
    "    return fid\n",
    "\n",
    "def expand_channels(data_list):\n",
    "    lx, ly, _ = data_list[0].shape\n",
    "    new_data = []\n",
    "    for data in data_list:\n",
    "        expanded_data = np.zeros((lx, ly, 3))\n",
    "        expanded_data[:,:,0] = data[:,:,0]\n",
    "        data_fft = np.fft.fftshift(np.fft.fft2(data[:,:,0]))\n",
    "        rfft = data_fft.real \n",
    "        ifft = data_fft.imag\n",
    "        power = rfft*rfft + ifft*ifft\n",
    "        #expanded_data[:,:,1] = np.log10(power)\n",
    "        expanded_data[:,:,1] = data[:,:,0]\n",
    "        expanded_data[:,:,2] = data[:,:,0]\n",
    "        new_data.append(expanded_data) \n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = \"sample_data\"\n",
    "\n",
    "gaussian   = 0.1 \n",
    "\n",
    "parent_dir = \".../cyclegan/\"\n",
    "\n",
    "exp_dir_raw = parent_dir + \"data/exp/sample_data_exp/\"\n",
    "sim_dir_raw = parent_dir + \"data/sim/sample_data_synth/\"\n",
    "\n",
    "exp_dir = exp_dir_raw[:-1] + \"_256_slices/\"\n",
    "sim_dir = sim_dir_raw[:-1] + \"_gauss_{}_256_slices/\".format(gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exp = preprocess_input(expand_channels(load_dataset(exp_dir)))\n",
    "fid_scores = []\n",
    "for i in range(41):\n",
    "    ganned_dir = parent_dir + \"data/GAN/exp/{}_CKPT_{}/\".format(identifier, i)\n",
    "    image_gan = preprocess_input(expand_channels(load_dataset(ganned_dir)))\n",
    "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(256,256,3))\n",
    "    fid = calculate_fid(model, image_exp, image_gan)\n",
    "    print('       idx: {}     FID (exp, gan): {:.3f}'.format(i, fid))\n",
    "    fid_scores.append(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(8,4), dpi=150)\n",
    "x = [(i+1)*10 for i in range(len(fid_scores))]\n",
    "plt.plot(x, fid_scores, '.-')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"FID\")\n",
    "plt.title(\"FID for each epoch\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"min FID: \", min(fid_scores))\n",
    "print(\"min FID ckpt: \", np.argmin(fid_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
